{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "\n",
    "right_ans = ['позитивный', 'позитивный', 'позитивный', 'позитивный', 'позитивный', 'негативный', 'негативный', 'негативный', 'негативный', 'негативный']\n",
    "results = []   \n",
    "def define_tonality(review, set_positive, set_negative):\n",
    "    global right_ans\n",
    "    global results\n",
    "    print('hello')\n",
    "    if review != '':\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        all_tokens = ''\n",
    "        py_tags = []\n",
    "        tokens = nltk.word_tokenize(review)\n",
    "        for token in tokens:\n",
    "            if token not in '.-?,!:;—»«':\n",
    "                p = m.parse(token)\n",
    "                POS = p[0].tag.POS\n",
    "                t = (p[0].word, POS)\n",
    "                py_tags.append(t)\n",
    "        ne_adjs = []\n",
    "        ne_adj = []\n",
    "        ochen_adjs = []\n",
    "        ochen_adj = []\n",
    "        for ind in range(len(py_tags)):\n",
    "            if ind == len(py_tags):\n",
    "                pass\n",
    "            elif py_tags[ind][0] == 'не' and py_tags[ind+1][1] == 'VERB':\n",
    "                ne_adj.append(py_tags[ind][0])\n",
    "                ne_adj.append(py_tags[ind+1][0])\n",
    "                ne_adjs.append(ne_adj)\n",
    "                ne_adj = []\n",
    "            elif py_tags[ind][0] == 'очень' and py_tags[ind+1][1] == 'ADJF':\n",
    "                ochen_adj.append(py_tags[ind][0])\n",
    "                ochen_adj.append(py_tags[ind+1][0])\n",
    "                ochen_adjs.append(ochen_adj)\n",
    "                ochen_adj = []\n",
    "        pos += len(ochen_adjs)\n",
    "        neg += len(ne_adjs)\n",
    "        lemmas = m.lemmatize(all_tokens)\n",
    "        for lemma in lemmas:\n",
    "            if lemma in set_positive:\n",
    "                pos += 1\n",
    "            if lemma in set_negative:\n",
    "                neg += 1\n",
    "        if neg > pos:\n",
    "            results.append('негативный')\n",
    "        else:\n",
    "            results.append('позитивный')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_accuracy(set_positive, set_negative):\n",
    "    print('re')\n",
    "    with open('test_pos.txt', encoding = 'utf-8') as f:\n",
    "        reviews = f.read()\n",
    "        for review in reviews.splitlines():\n",
    "            define_tonality(review, set_positive, set_negative)\n",
    "            n_grams(review)\n",
    "        \n",
    "    with open('test_neg.txt', encoding = 'utf-8') as f:\n",
    "        reviews = f.read()\n",
    "        for review in reviews.splitlines():\n",
    "            define_tonality(review, set_positive, set_negative)\n",
    "    print(accuracy_score(results, right_ans))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sets(lemmas_pos, lemmas_neg):\n",
    "    fil_lemmas_pos = []\n",
    "    fil_lemmas_neg = []\n",
    "    for lemma in lemmas_pos:\n",
    "        if lemma != ' ' and lemmas_pos.count(lemma) > 2:\n",
    "            fil_lemmas_pos.append(lemma)\n",
    "    for lemma in lemmas_neg:\n",
    "        if lemma != ' ' and lemmas_neg.count(lemma) > 2:\n",
    "            fil_lemmas_neg.append(lemma)\n",
    "    set_positive = set(fil_lemmas_pos)\n",
    "    set_negative = set(fil_lemmas_neg)\n",
    "    count_accuracy(set_positive, set_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predprocessing():\n",
    "    with open('positive.txt', encoding = 'utf-8') as f:\n",
    "        all_tokens = ''\n",
    "        reviews = f.read()\n",
    "        tokens = nltk.word_tokenize(reviews)\n",
    "        for token in tokens:\n",
    "            if token.isalpha() and token not in stop_words:\n",
    "                all_tokens = all_tokens + ' ' + token\n",
    "        lemmas_pos = m.lemmatize(all_tokens)\n",
    "    with open('negative.txt', encoding = 'utf-8') as f:\n",
    "        all_tokens = ''\n",
    "        reviews = f.read()\n",
    "        tokens = nltk.word_tokenize(reviews)\n",
    "        for token in tokens:\n",
    "            if token.isalpha() and token not in stop_words:\n",
    "                all_tokens = all_tokens + ' ' + token\n",
    "        lemmas_neg = m.lemmatize(all_tokens)\n",
    "    create_sets(lemmas_pos, lemmas_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель можно было бы улучшить, добавить стоп-слова (что я сделала выше), а также возможно было полезным смотреть не только на слова, но и на коллокации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "m = MorphAnalyzer\n",
    "def n_grams(review):\n",
    "    py_tags = []\n",
    "    tokens = nltk.word_tokenize(review)\n",
    "    for token in tokens:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
